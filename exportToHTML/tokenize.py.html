<html>
<head>
<title>tokenize.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.ln { color: #606366; font-weight: normal; font-style: normal; }
.s0 { color: rgb(98,151,85); font-style: italic; }
.s1 { color: rgb(169,183,198); }
.s2 { color: rgb(106,135,89); }
.s3 { color: rgb(204,120,50); }
.s4 { color: rgb(165,194,97); }
.s5 { color: rgb(104,151,187); }
.s6 { color: rgb(128,128,128); }
</style>
</head>
<BODY BGCOLOR="#2b2b2b">
<TABLE CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<TR><TD><CENTER>
<FONT FACE="Arial, Helvetica" COLOR="#000000">
tokenize.py</FONT>
</center></TD></TR></TABLE>
<pre>
<span class="s0">&quot;&quot;&quot;Tokenization help for Python programs. 
 
tokenize(readline) is a generator that breaks a stream of bytes into 
Python tokens.  It decodes the bytes according to PEP-0263 for 
determining source file encoding. 
 
It accepts a readline-like method which is called repeatedly to get the 
next line of input (or b&quot;&quot; for EOF).  It generates 5-tuples with these 
members: 
 
    the token type (see token.py) 
    the token (a string) 
    the starting (row, column) indices of the token (a 2-tuple of ints) 
    the ending (row, column) indices of the token (a 2-tuple of ints) 
    the original line (string) 
 
It is designed to match the working of the Python tokenizer exactly, except 
that it produces COMMENT tokens for comments and gives type OP for all 
operators.  Additionally, all token lists start with an ENCODING token 
which tells you which encoding was used to decode the bytes stream. 
&quot;&quot;&quot;</span><span class="s1"> 
 
__author__ = </span><span class="s2">'Ka-Ping Yee &lt;ping@lfw.org&gt;'</span><span class="s1"> 
__credits__ = (</span><span class="s2">'GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, '</span><span class="s1"> 
               </span><span class="s2">'Skip Montanaro, Raymond Hettinger, Trent Nelson, '</span><span class="s1"> 
               </span><span class="s2">'Michael Foord'</span><span class="s1">) 
</span><span class="s3">from </span><span class="s1">builtins </span><span class="s3">import </span><span class="s1">open </span><span class="s3">as </span><span class="s1">_builtin_open 
</span><span class="s3">from </span><span class="s1">codecs </span><span class="s3">import </span><span class="s1">lookup</span><span class="s3">, </span><span class="s1">BOM_UTF8 
</span><span class="s3">import </span><span class="s1">collections 
</span><span class="s3">from </span><span class="s1">io </span><span class="s3">import </span><span class="s1">TextIOWrapper 
</span><span class="s3">from </span><span class="s1">itertools </span><span class="s3">import </span><span class="s1">chain 
</span><span class="s3">import </span><span class="s1">re 
</span><span class="s3">import </span><span class="s1">sys 
</span><span class="s3">from </span><span class="s1">token </span><span class="s3">import </span><span class="s1">* 
 
cookie_re = re.compile(</span><span class="s2">r'^[ \t\f]*#.*?coding[:=][ \t]*([-\w.]+)'</span><span class="s3">, </span><span class="s1">re.ASCII) 
blank_re = re.compile(</span><span class="s4">br'^[ \t\f]*(?:[#\r\n]|$)'</span><span class="s3">, </span><span class="s1">re.ASCII) 
 
</span><span class="s3">import </span><span class="s1">token 
__all__ = token.__all__ + [</span><span class="s2">&quot;COMMENT&quot;</span><span class="s3">, </span><span class="s2">&quot;tokenize&quot;</span><span class="s3">, </span><span class="s2">&quot;detect_encoding&quot;</span><span class="s3">,</span><span class="s1"> 
                           </span><span class="s2">&quot;NL&quot;</span><span class="s3">, </span><span class="s2">&quot;untokenize&quot;</span><span class="s3">, </span><span class="s2">&quot;ENCODING&quot;</span><span class="s3">, </span><span class="s2">&quot;TokenInfo&quot;</span><span class="s1">] 
</span><span class="s3">del </span><span class="s1">token 
 
COMMENT = N_TOKENS 
tok_name[COMMENT] = </span><span class="s2">'COMMENT'</span><span class="s1"> 
NL = N_TOKENS + </span><span class="s5">1</span><span class="s1"> 
tok_name[NL] = </span><span class="s2">'NL'</span><span class="s1"> 
ENCODING = N_TOKENS + </span><span class="s5">2</span><span class="s1"> 
tok_name[ENCODING] = </span><span class="s2">'ENCODING'</span><span class="s1"> 
N_TOKENS += </span><span class="s5">3</span><span class="s1"> 
EXACT_TOKEN_TYPES = { 
    </span><span class="s2">'('</span><span class="s1">:   LPAR</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">')'</span><span class="s1">:   RPAR</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'['</span><span class="s1">:   LSQB</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">']'</span><span class="s1">:   RSQB</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">':'</span><span class="s1">:   COLON</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">','</span><span class="s1">:   COMMA</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">';'</span><span class="s1">:   SEMI</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'+'</span><span class="s1">:   PLUS</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'-'</span><span class="s1">:   MINUS</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'*'</span><span class="s1">:   STAR</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'/'</span><span class="s1">:   SLASH</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'|'</span><span class="s1">:   VBAR</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'&amp;'</span><span class="s1">:   AMPER</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'&lt;'</span><span class="s1">:   LESS</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'&gt;'</span><span class="s1">:   GREATER</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'='</span><span class="s1">:   EQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'.'</span><span class="s1">:   DOT</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'%'</span><span class="s1">:   PERCENT</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'{'</span><span class="s1">:   LBRACE</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'}'</span><span class="s1">:   RBRACE</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'=='</span><span class="s1">:  EQEQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'!='</span><span class="s1">:  NOTEQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'&lt;='</span><span class="s1">:  LESSEQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'&gt;='</span><span class="s1">:  GREATEREQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'~'</span><span class="s1">:   TILDE</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'^'</span><span class="s1">:   CIRCUMFLEX</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'&lt;&lt;'</span><span class="s1">:  LEFTSHIFT</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'&gt;&gt;'</span><span class="s1">:  RIGHTSHIFT</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'**'</span><span class="s1">:  DOUBLESTAR</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'+='</span><span class="s1">:  PLUSEQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'-='</span><span class="s1">:  MINEQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'*='</span><span class="s1">:  STAREQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'/='</span><span class="s1">:  SLASHEQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'%='</span><span class="s1">:  PERCENTEQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'&amp;='</span><span class="s1">:  AMPEREQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'|='</span><span class="s1">:  VBAREQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'^='</span><span class="s1">: CIRCUMFLEXEQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'&lt;&lt;='</span><span class="s1">: LEFTSHIFTEQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'&gt;&gt;='</span><span class="s1">: RIGHTSHIFTEQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'**='</span><span class="s1">: DOUBLESTAREQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'//'</span><span class="s1">:  DOUBLESLASH</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'//='</span><span class="s1">: DOUBLESLASHEQUAL</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'@'</span><span class="s1">:   AT</span><span class="s3">,</span><span class="s1"> 
    </span><span class="s2">'@='</span><span class="s1">:  ATEQUAL</span><span class="s3">,</span><span class="s1"> 
} 
 
</span><span class="s3">class </span><span class="s1">TokenInfo(collections.namedtuple(</span><span class="s2">'TokenInfo'</span><span class="s3">, </span><span class="s2">'type string start end line'</span><span class="s1">)): 
    </span><span class="s3">def </span><span class="s1">__repr__(self): 
        annotated_type = </span><span class="s2">'%d (%s)' </span><span class="s1">% (self.type</span><span class="s3">, </span><span class="s1">tok_name[self.type]) 
        </span><span class="s3">return </span><span class="s1">(</span><span class="s2">'TokenInfo(type=%s, string=%r, start=%r, end=%r, line=%r)' </span><span class="s1">% 
                self._replace(type=annotated_type)) 
 
    @property 
    </span><span class="s3">def </span><span class="s1">exact_type(self): 
        </span><span class="s3">if </span><span class="s1">self.type == OP </span><span class="s3">and </span><span class="s1">self.string </span><span class="s3">in </span><span class="s1">EXACT_TOKEN_TYPES: 
            </span><span class="s3">return </span><span class="s1">EXACT_TOKEN_TYPES[self.string] 
        </span><span class="s3">else</span><span class="s1">: 
            </span><span class="s3">return </span><span class="s1">self.type 
 
</span><span class="s3">def </span><span class="s1">group(*choices): </span><span class="s3">return </span><span class="s2">'(' </span><span class="s1">+ </span><span class="s2">'|'</span><span class="s1">.join(choices) + </span><span class="s2">')'</span><span class="s1"> 
</span><span class="s3">def </span><span class="s1">any(*choices): </span><span class="s3">return </span><span class="s1">group(*choices) + </span><span class="s2">'*'</span><span class="s1"> 
</span><span class="s3">def </span><span class="s1">maybe(*choices): </span><span class="s3">return </span><span class="s1">group(*choices) + </span><span class="s2">'?'</span><span class="s1"> 
 
</span><span class="s6"># Note: we use unicode matching for names (&quot;\w&quot;) but ascii matching for</span><span class="s1"> 
</span><span class="s6"># number literals.</span><span class="s1"> 
Whitespace = </span><span class="s2">r'[ \f\t]*'</span><span class="s1"> 
Comment = </span><span class="s2">r'#[^\r\n]*'</span><span class="s1"> 
Ignore = Whitespace + any(</span><span class="s2">r'\\\r?\n' </span><span class="s1">+ Whitespace) + maybe(Comment) 
Name = </span><span class="s2">r'\w+'</span><span class="s1"> 
 
Hexnumber = </span><span class="s2">r'0[xX][0-9a-fA-F]+'</span><span class="s1"> 
Binnumber = </span><span class="s2">r'0[bB][01]+'</span><span class="s1"> 
Octnumber = </span><span class="s2">r'0[oO][0-7]+'</span><span class="s1"> 
Decnumber = </span><span class="s2">r'(?:0+|[1-9][0-9]*)'</span><span class="s1"> 
Intnumber = group(Hexnumber</span><span class="s3">, </span><span class="s1">Binnumber</span><span class="s3">, </span><span class="s1">Octnumber</span><span class="s3">, </span><span class="s1">Decnumber) 
Exponent = </span><span class="s2">r'[eE][-+]?[0-9]+'</span><span class="s1"> 
Pointfloat = group(</span><span class="s2">r'[0-9]+\.[0-9]*'</span><span class="s3">, </span><span class="s2">r'\.[0-9]+'</span><span class="s1">) + maybe(Exponent) 
Expfloat = </span><span class="s2">r'[0-9]+' </span><span class="s1">+ Exponent 
Floatnumber = group(Pointfloat</span><span class="s3">, </span><span class="s1">Expfloat) 
Imagnumber = group(</span><span class="s2">r'[0-9]+[jJ]'</span><span class="s3">, </span><span class="s1">Floatnumber + </span><span class="s2">r'[jJ]'</span><span class="s1">) 
Number = group(Imagnumber</span><span class="s3">, </span><span class="s1">Floatnumber</span><span class="s3">, </span><span class="s1">Intnumber) 
 
StringPrefix = </span><span class="s2">r'(?:[bB][rR]?|[rR][bB]?|[uU])?'</span><span class="s1"> 
 
</span><span class="s6"># Tail end of ' string.</span><span class="s1"> 
Single = </span><span class="s2">r&quot;[^'\\]*(?:\\.[^'\\]*)*'&quot;</span><span class="s1"> 
</span><span class="s6"># Tail end of &quot; string.</span><span class="s1"> 
Double = </span><span class="s2">r'[^&quot;\\]*(?:\\.[^&quot;\\]*)*&quot;'</span><span class="s1"> 
</span><span class="s6"># Tail end of ''' string.</span><span class="s1"> 
Single3 = </span><span class="s2">r&quot;[^'\\]*(?:(?:\\.|'(?!''))[^'\\]*)*'''&quot;</span><span class="s1"> 
</span><span class="s6"># Tail end of &quot;&quot;&quot; string.</span><span class="s1"> 
Double3 = </span><span class="s2">r'[^&quot;\\]*(?:(?:\\.|&quot;(?!&quot;&quot;))[^&quot;\\]*)*&quot;&quot;&quot;'</span><span class="s1"> 
Triple = group(StringPrefix + </span><span class="s2">&quot;'''&quot;</span><span class="s3">, </span><span class="s1">StringPrefix + </span><span class="s2">'&quot;&quot;&quot;'</span><span class="s1">) 
</span><span class="s6"># Single-line ' or &quot; string.</span><span class="s1"> 
String = group(StringPrefix + </span><span class="s2">r&quot;'[^\n'\\]*(?:\\.[^\n'\\]*)*'&quot;</span><span class="s3">,</span><span class="s1"> 
               StringPrefix + </span><span class="s2">r'&quot;[^\n&quot;\\]*(?:\\.[^\n&quot;\\]*)*&quot;'</span><span class="s1">) 
 
</span><span class="s6"># Because of leftmost-then-longest match semantics, be sure to put the</span><span class="s1"> 
</span><span class="s6"># longest operators first (e.g., if = came before ==, == would get</span><span class="s1"> 
</span><span class="s6"># recognized as two instances of =).</span><span class="s1"> 
Operator = group(</span><span class="s2">r&quot;\*\*=?&quot;</span><span class="s3">, </span><span class="s2">r&quot;&gt;&gt;=?&quot;</span><span class="s3">, </span><span class="s2">r&quot;&lt;&lt;=?&quot;</span><span class="s3">, </span><span class="s2">r&quot;!=&quot;</span><span class="s3">,</span><span class="s1"> 
                 </span><span class="s2">r&quot;//=?&quot;</span><span class="s3">, </span><span class="s2">r&quot;-&gt;&quot;</span><span class="s3">,</span><span class="s1"> 
                 </span><span class="s2">r&quot;[+\-*/%&amp;@|^=&lt;&gt;]=?&quot;</span><span class="s3">,</span><span class="s1"> 
                 </span><span class="s2">r&quot;~&quot;</span><span class="s1">) 
 
Bracket = </span><span class="s2">'[][(){}]'</span><span class="s1"> 
Special = group(</span><span class="s2">r'\r?\n'</span><span class="s3">, </span><span class="s2">r'\.\.\.'</span><span class="s3">, </span><span class="s2">r'[:;.,@]'</span><span class="s1">) 
Funny = group(Operator</span><span class="s3">, </span><span class="s1">Bracket</span><span class="s3">, </span><span class="s1">Special) 
 
PlainToken = group(Number</span><span class="s3">, </span><span class="s1">Funny</span><span class="s3">, </span><span class="s1">String</span><span class="s3">, </span><span class="s1">Name) 
Token = Ignore + PlainToken 
 
</span><span class="s6"># First (or only) line of ' or &quot; string.</span><span class="s1"> 
ContStr = group(StringPrefix + </span><span class="s2">r&quot;'[^\n'\\]*(?:\\.[^\n'\\]*)*&quot; </span><span class="s1">+ 
                group(</span><span class="s2">&quot;'&quot;</span><span class="s3">, </span><span class="s2">r'\\\r?\n'</span><span class="s1">)</span><span class="s3">,</span><span class="s1"> 
                StringPrefix + </span><span class="s2">r'&quot;[^\n&quot;\\]*(?:\\.[^\n&quot;\\]*)*' </span><span class="s1">+ 
                group(</span><span class="s2">'&quot;'</span><span class="s3">, </span><span class="s2">r'\\\r?\n'</span><span class="s1">)) 
PseudoExtras = group(</span><span class="s2">r'\\\r?\n|\Z'</span><span class="s3">, </span><span class="s1">Comment</span><span class="s3">, </span><span class="s1">Triple) 
PseudoToken = Whitespace + group(PseudoExtras</span><span class="s3">, </span><span class="s1">Number</span><span class="s3">, </span><span class="s1">Funny</span><span class="s3">, </span><span class="s1">ContStr</span><span class="s3">, </span><span class="s1">Name) 
 
</span><span class="s3">def </span><span class="s1">_compile(expr): 
    </span><span class="s3">return </span><span class="s1">re.compile(expr</span><span class="s3">, </span><span class="s1">re.UNICODE) 
 
endpats = {</span><span class="s2">&quot;'&quot;</span><span class="s1">: Single</span><span class="s3">, </span><span class="s2">'&quot;'</span><span class="s1">: Double</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;r'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'r&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;b'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'b&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;R'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'R&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;B'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'B&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;br'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'br&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;bR'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'bR&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;Br'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'Br&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;BR'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'BR&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;rb'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'rb&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;Rb'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'Rb&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;rB'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'rB&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;RB'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'RB&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;u'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'u&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">&quot;U'''&quot;</span><span class="s1">: Single3</span><span class="s3">, </span><span class="s2">'U&quot;&quot;&quot;'</span><span class="s1">: Double3</span><span class="s3">,</span><span class="s1"> 
           </span><span class="s2">'r'</span><span class="s1">: </span><span class="s3">None, </span><span class="s2">'R'</span><span class="s1">: </span><span class="s3">None, </span><span class="s2">'b'</span><span class="s1">: </span><span class="s3">None, </span><span class="s2">'B'</span><span class="s1">: </span><span class="s3">None,</span><span class="s1"> 
           </span><span class="s2">'u'</span><span class="s1">: </span><span class="s3">None, </span><span class="s2">'U'</span><span class="s1">: </span><span class="s3">None</span><span class="s1">} 
 
triple_quoted = {} 
</span><span class="s3">for </span><span class="s1">t </span><span class="s3">in </span><span class="s1">(</span><span class="s2">&quot;'''&quot;</span><span class="s3">, </span><span class="s2">'&quot;&quot;&quot;'</span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;r'''&quot;</span><span class="s3">, </span><span class="s2">'r&quot;&quot;&quot;'</span><span class="s3">, </span><span class="s2">&quot;R'''&quot;</span><span class="s3">, </span><span class="s2">'R&quot;&quot;&quot;'</span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;b'''&quot;</span><span class="s3">, </span><span class="s2">'b&quot;&quot;&quot;'</span><span class="s3">, </span><span class="s2">&quot;B'''&quot;</span><span class="s3">, </span><span class="s2">'B&quot;&quot;&quot;'</span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;br'''&quot;</span><span class="s3">, </span><span class="s2">'br&quot;&quot;&quot;'</span><span class="s3">, </span><span class="s2">&quot;Br'''&quot;</span><span class="s3">, </span><span class="s2">'Br&quot;&quot;&quot;'</span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;bR'''&quot;</span><span class="s3">, </span><span class="s2">'bR&quot;&quot;&quot;'</span><span class="s3">, </span><span class="s2">&quot;BR'''&quot;</span><span class="s3">, </span><span class="s2">'BR&quot;&quot;&quot;'</span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;rb'''&quot;</span><span class="s3">, </span><span class="s2">'rb&quot;&quot;&quot;'</span><span class="s3">, </span><span class="s2">&quot;rB'''&quot;</span><span class="s3">, </span><span class="s2">'rB&quot;&quot;&quot;'</span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;Rb'''&quot;</span><span class="s3">, </span><span class="s2">'Rb&quot;&quot;&quot;'</span><span class="s3">, </span><span class="s2">&quot;RB'''&quot;</span><span class="s3">, </span><span class="s2">'RB&quot;&quot;&quot;'</span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;u'''&quot;</span><span class="s3">, </span><span class="s2">'u&quot;&quot;&quot;'</span><span class="s3">, </span><span class="s2">&quot;U'''&quot;</span><span class="s3">, </span><span class="s2">'U&quot;&quot;&quot;'</span><span class="s3">,</span><span class="s1"> 
          ): 
    triple_quoted[t] = t 
single_quoted = {} 
</span><span class="s3">for </span><span class="s1">t </span><span class="s3">in </span><span class="s1">(</span><span class="s2">&quot;'&quot;</span><span class="s3">, </span><span class="s2">'&quot;'</span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;r'&quot;</span><span class="s3">, </span><span class="s2">'r&quot;'</span><span class="s3">, </span><span class="s2">&quot;R'&quot;</span><span class="s3">, </span><span class="s2">'R&quot;'</span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;b'&quot;</span><span class="s3">, </span><span class="s2">'b&quot;'</span><span class="s3">, </span><span class="s2">&quot;B'&quot;</span><span class="s3">, </span><span class="s2">'B&quot;'</span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;br'&quot;</span><span class="s3">, </span><span class="s2">'br&quot;'</span><span class="s3">, </span><span class="s2">&quot;Br'&quot;</span><span class="s3">, </span><span class="s2">'Br&quot;'</span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;bR'&quot;</span><span class="s3">, </span><span class="s2">'bR&quot;'</span><span class="s3">, </span><span class="s2">&quot;BR'&quot;</span><span class="s3">, </span><span class="s2">'BR&quot;' </span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;rb'&quot;</span><span class="s3">, </span><span class="s2">'rb&quot;'</span><span class="s3">, </span><span class="s2">&quot;rB'&quot;</span><span class="s3">, </span><span class="s2">'rB&quot;'</span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;Rb'&quot;</span><span class="s3">, </span><span class="s2">'Rb&quot;'</span><span class="s3">, </span><span class="s2">&quot;RB'&quot;</span><span class="s3">, </span><span class="s2">'RB&quot;' </span><span class="s3">,</span><span class="s1"> 
          </span><span class="s2">&quot;u'&quot;</span><span class="s3">, </span><span class="s2">'u&quot;'</span><span class="s3">, </span><span class="s2">&quot;U'&quot;</span><span class="s3">, </span><span class="s2">'U&quot;'</span><span class="s3">,</span><span class="s1"> 
          ): 
    single_quoted[t] = t 
 
tabsize = </span><span class="s5">8</span><span class="s1"> 
 
</span><span class="s3">class </span><span class="s1">TokenError(Exception): </span><span class="s3">pass</span><span class="s1"> 
 
</span><span class="s3">class </span><span class="s1">StopTokenizing(Exception): </span><span class="s3">pass</span><span class="s1"> 
 
 
</span><span class="s3">class </span><span class="s1">Untokenizer: 
 
    </span><span class="s3">def </span><span class="s1">__init__(self): 
        self.tokens = [] 
        self.prev_row = </span><span class="s5">1</span><span class="s1"> 
        self.prev_col = </span><span class="s5">0</span><span class="s1"> 
        self.encoding = </span><span class="s3">None</span><span class="s1"> 
 
    </span><span class="s3">def </span><span class="s1">add_whitespace(self</span><span class="s3">, </span><span class="s1">start): 
        row</span><span class="s3">, </span><span class="s1">col = start 
        </span><span class="s3">if </span><span class="s1">row &lt; self.prev_row </span><span class="s3">or </span><span class="s1">row == self.prev_row </span><span class="s3">and </span><span class="s1">col &lt; self.prev_col: 
            </span><span class="s3">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;start ({},{}) precedes previous end ({},{})&quot;</span><span class="s1"> 
                             .format(row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">self.prev_row</span><span class="s3">, </span><span class="s1">self.prev_col)) 
        row_offset = row - self.prev_row 
        </span><span class="s3">if </span><span class="s1">row_offset: 
            self.tokens.append(</span><span class="s2">&quot;</span><span class="s3">\\\n</span><span class="s2">&quot; </span><span class="s1">* row_offset) 
            self.prev_col = </span><span class="s5">0</span><span class="s1"> 
        col_offset = col - self.prev_col 
        </span><span class="s3">if </span><span class="s1">col_offset: 
            self.tokens.append(</span><span class="s2">&quot; &quot; </span><span class="s1">* col_offset) 
 
    </span><span class="s3">def </span><span class="s1">untokenize(self</span><span class="s3">, </span><span class="s1">iterable): 
        it = iter(iterable) 
        indents = [] 
        startline = </span><span class="s3">False</span><span class="s1"> 
        </span><span class="s3">for </span><span class="s1">t </span><span class="s3">in </span><span class="s1">it: 
            </span><span class="s3">if </span><span class="s1">len(t) == </span><span class="s5">2</span><span class="s1">: 
                self.compat(t</span><span class="s3">, </span><span class="s1">it) 
                </span><span class="s3">break</span><span class="s1"> 
            tok_type</span><span class="s3">, </span><span class="s1">token</span><span class="s3">, </span><span class="s1">start</span><span class="s3">, </span><span class="s1">end</span><span class="s3">, </span><span class="s1">line = t 
            </span><span class="s3">if </span><span class="s1">tok_type == ENCODING: 
                self.encoding = token 
                </span><span class="s3">continue</span><span class="s1"> 
            </span><span class="s3">if </span><span class="s1">tok_type == ENDMARKER: 
                </span><span class="s3">break</span><span class="s1"> 
            </span><span class="s3">if </span><span class="s1">tok_type == INDENT: 
                indents.append(token) 
                </span><span class="s3">continue</span><span class="s1"> 
            </span><span class="s3">elif </span><span class="s1">tok_type == DEDENT: 
                indents.pop() 
                self.prev_row</span><span class="s3">, </span><span class="s1">self.prev_col = end 
                </span><span class="s3">continue</span><span class="s1"> 
            </span><span class="s3">elif </span><span class="s1">tok_type </span><span class="s3">in </span><span class="s1">(NEWLINE</span><span class="s3">, </span><span class="s1">NL): 
                startline = </span><span class="s3">True</span><span class="s1"> 
            </span><span class="s3">elif </span><span class="s1">startline </span><span class="s3">and </span><span class="s1">indents: 
                indent = indents[-</span><span class="s5">1</span><span class="s1">] 
                </span><span class="s3">if </span><span class="s1">start[</span><span class="s5">1</span><span class="s1">] &gt;= len(indent): 
                    self.tokens.append(indent) 
                    self.prev_col = len(indent) 
                startline = </span><span class="s3">False</span><span class="s1"> 
            self.add_whitespace(start) 
            self.tokens.append(token) 
            self.prev_row</span><span class="s3">, </span><span class="s1">self.prev_col = end 
            </span><span class="s3">if </span><span class="s1">tok_type </span><span class="s3">in </span><span class="s1">(NEWLINE</span><span class="s3">, </span><span class="s1">NL): 
                self.prev_row += </span><span class="s5">1</span><span class="s1"> 
                self.prev_col = </span><span class="s5">0</span><span class="s1"> 
        </span><span class="s3">return </span><span class="s2">&quot;&quot;</span><span class="s1">.join(self.tokens) 
 
    </span><span class="s3">def </span><span class="s1">compat(self</span><span class="s3">, </span><span class="s1">token</span><span class="s3">, </span><span class="s1">iterable): 
        indents = [] 
        toks_append = self.tokens.append 
        startline = token[</span><span class="s5">0</span><span class="s1">] </span><span class="s3">in </span><span class="s1">(NEWLINE</span><span class="s3">, </span><span class="s1">NL) 
        prevstring = </span><span class="s3">False</span><span class="s1"> 
 
        </span><span class="s3">for </span><span class="s1">tok </span><span class="s3">in </span><span class="s1">chain([token]</span><span class="s3">, </span><span class="s1">iterable): 
            toknum</span><span class="s3">, </span><span class="s1">tokval = tok[:</span><span class="s5">2</span><span class="s1">] 
            </span><span class="s3">if </span><span class="s1">toknum == ENCODING: 
                self.encoding = tokval 
                </span><span class="s3">continue</span><span class="s1"> 
 
            </span><span class="s3">if </span><span class="s1">toknum </span><span class="s3">in </span><span class="s1">(NAME</span><span class="s3">, </span><span class="s1">NUMBER</span><span class="s3">, </span><span class="s1">ASYNC</span><span class="s3">, </span><span class="s1">AWAIT): 
                tokval += </span><span class="s2">' '</span><span class="s1"> 
 
            </span><span class="s6"># Insert a space between two consecutive strings</span><span class="s1"> 
            </span><span class="s3">if </span><span class="s1">toknum == STRING: 
                </span><span class="s3">if </span><span class="s1">prevstring: 
                    tokval = </span><span class="s2">' ' </span><span class="s1">+ tokval 
                prevstring = </span><span class="s3">True</span><span class="s1"> 
            </span><span class="s3">else</span><span class="s1">: 
                prevstring = </span><span class="s3">False</span><span class="s1"> 
 
            </span><span class="s3">if </span><span class="s1">toknum == INDENT: 
                indents.append(tokval) 
                </span><span class="s3">continue</span><span class="s1"> 
            </span><span class="s3">elif </span><span class="s1">toknum == DEDENT: 
                indents.pop() 
                </span><span class="s3">continue</span><span class="s1"> 
            </span><span class="s3">elif </span><span class="s1">toknum </span><span class="s3">in </span><span class="s1">(NEWLINE</span><span class="s3">, </span><span class="s1">NL): 
                startline = </span><span class="s3">True</span><span class="s1"> 
            </span><span class="s3">elif </span><span class="s1">startline </span><span class="s3">and </span><span class="s1">indents: 
                toks_append(indents[-</span><span class="s5">1</span><span class="s1">]) 
                startline = </span><span class="s3">False</span><span class="s1"> 
            toks_append(tokval) 
 
 
</span><span class="s3">def </span><span class="s1">untokenize(iterable): 
    </span><span class="s0">&quot;&quot;&quot;Transform tokens back into Python source code. 
    It returns a bytes object, encoded using the ENCODING 
    token, which is the first token sequence output by tokenize. 
 
    Each element returned by the iterable must be a token sequence 
    with at least two elements, a token number and token value.  If 
    only two tokens are passed, the resulting output is poor. 
 
    Round-trip invariant for full input: 
        Untokenized source will match input source exactly 
 
    Round-trip invariant for limited input: 
        # Output bytes will tokenize back to the input 
        t1 = [tok[:2] for tok in tokenize(f.readline)] 
        newcode = untokenize(t1) 
        readline = BytesIO(newcode).readline 
        t2 = [tok[:2] for tok in tokenize(readline)] 
        assert t1 == t2 
    &quot;&quot;&quot;</span><span class="s1"> 
    ut = Untokenizer() 
    out = ut.untokenize(iterable) 
    </span><span class="s3">if </span><span class="s1">ut.encoding </span><span class="s3">is not None</span><span class="s1">: 
        out = out.encode(ut.encoding) 
    </span><span class="s3">return </span><span class="s1">out 
 
 
</span><span class="s3">def </span><span class="s1">_get_normal_name(orig_enc): 
    </span><span class="s0">&quot;&quot;&quot;Imitates get_normal_name in tokenizer.c.&quot;&quot;&quot;</span><span class="s1"> 
    </span><span class="s6"># Only care about the first 12 characters.</span><span class="s1"> 
    enc = orig_enc[:</span><span class="s5">12</span><span class="s1">].lower().replace(</span><span class="s2">&quot;_&quot;</span><span class="s3">, </span><span class="s2">&quot;-&quot;</span><span class="s1">) 
    </span><span class="s3">if </span><span class="s1">enc == </span><span class="s2">&quot;utf-8&quot; </span><span class="s3">or </span><span class="s1">enc.startswith(</span><span class="s2">&quot;utf-8-&quot;</span><span class="s1">): 
        </span><span class="s3">return </span><span class="s2">&quot;utf-8&quot;</span><span class="s1"> 
    </span><span class="s3">if </span><span class="s1">enc </span><span class="s3">in </span><span class="s1">(</span><span class="s2">&quot;latin-1&quot;</span><span class="s3">, </span><span class="s2">&quot;iso-8859-1&quot;</span><span class="s3">, </span><span class="s2">&quot;iso-latin-1&quot;</span><span class="s1">) </span><span class="s3">or </span><span class="s1">\ 
       enc.startswith((</span><span class="s2">&quot;latin-1-&quot;</span><span class="s3">, </span><span class="s2">&quot;iso-8859-1-&quot;</span><span class="s3">, </span><span class="s2">&quot;iso-latin-1-&quot;</span><span class="s1">)): 
        </span><span class="s3">return </span><span class="s2">&quot;iso-8859-1&quot;</span><span class="s1"> 
    </span><span class="s3">return </span><span class="s1">orig_enc 
 
</span><span class="s3">def </span><span class="s1">detect_encoding(readline): 
    </span><span class="s0">&quot;&quot;&quot; 
    The detect_encoding() function is used to detect the encoding that should 
    be used to decode a Python source file.  It requires one argument, readline, 
    in the same way as the tokenize() generator. 
 
    It will call readline a maximum of twice, and return the encoding used 
    (as a string) and a list of any lines (left as bytes) it has read in. 
 
    It detects the encoding from the presence of a utf-8 bom or an encoding 
    cookie as specified in pep-0263.  If both a bom and a cookie are present, 
    but disagree, a SyntaxError will be raised.  If the encoding cookie is an 
    invalid charset, raise a SyntaxError.  Note that if a utf-8 bom is found, 
    'utf-8-sig' is returned. 
 
    If no encoding is specified, then the default of 'utf-8' will be returned. 
    &quot;&quot;&quot;</span><span class="s1"> 
    </span><span class="s3">try</span><span class="s1">: 
        filename = readline.__self__.name 
    </span><span class="s3">except </span><span class="s1">AttributeError: 
        filename = </span><span class="s3">None</span><span class="s1"> 
    bom_found = </span><span class="s3">False</span><span class="s1"> 
    encoding = </span><span class="s3">None</span><span class="s1"> 
    default = </span><span class="s2">'utf-8'</span><span class="s1"> 
    </span><span class="s3">def </span><span class="s1">read_or_stop(): 
        </span><span class="s3">try</span><span class="s1">: 
            </span><span class="s3">return </span><span class="s1">readline() 
        </span><span class="s3">except </span><span class="s1">StopIteration: 
            </span><span class="s3">return </span><span class="s4">b''</span><span class="s1"> 
 
    </span><span class="s3">def </span><span class="s1">find_cookie(line): 
        </span><span class="s3">try</span><span class="s1">: 
            </span><span class="s6"># Decode as UTF-8. Either the line is an encoding declaration,</span><span class="s1"> 
            </span><span class="s6"># in which case it should be pure ASCII, or it must be UTF-8</span><span class="s1"> 
            </span><span class="s6"># per default encoding.</span><span class="s1"> 
            line_string = line.decode(</span><span class="s2">'utf-8'</span><span class="s1">) 
        </span><span class="s3">except </span><span class="s1">UnicodeDecodeError: 
            msg = </span><span class="s2">&quot;invalid or missing encoding declaration&quot;</span><span class="s1"> 
            </span><span class="s3">if </span><span class="s1">filename </span><span class="s3">is not None</span><span class="s1">: 
                msg = </span><span class="s2">'{} for {!r}'</span><span class="s1">.format(msg</span><span class="s3">, </span><span class="s1">filename) 
            </span><span class="s3">raise </span><span class="s1">SyntaxError(msg) 
 
        match = cookie_re.match(line_string) 
        </span><span class="s3">if not </span><span class="s1">match: 
            </span><span class="s3">return None</span><span class="s1"> 
        encoding = _get_normal_name(match.group(</span><span class="s5">1</span><span class="s1">)) 
        </span><span class="s3">try</span><span class="s1">: 
            codec = lookup(encoding) 
        </span><span class="s3">except </span><span class="s1">LookupError: 
            </span><span class="s6"># This behaviour mimics the Python interpreter</span><span class="s1"> 
            </span><span class="s3">if </span><span class="s1">filename </span><span class="s3">is None</span><span class="s1">: 
                msg = </span><span class="s2">&quot;unknown encoding: &quot; </span><span class="s1">+ encoding 
            </span><span class="s3">else</span><span class="s1">: 
                msg = </span><span class="s2">&quot;unknown encoding for {!r}: {}&quot;</span><span class="s1">.format(filename</span><span class="s3">,</span><span class="s1"> 
                        encoding) 
            </span><span class="s3">raise </span><span class="s1">SyntaxError(msg) 
 
        </span><span class="s3">if </span><span class="s1">bom_found: 
            </span><span class="s3">if </span><span class="s1">encoding != </span><span class="s2">'utf-8'</span><span class="s1">: 
                </span><span class="s6"># This behaviour mimics the Python interpreter</span><span class="s1"> 
                </span><span class="s3">if </span><span class="s1">filename </span><span class="s3">is None</span><span class="s1">: 
                    msg = </span><span class="s2">'encoding problem: utf-8'</span><span class="s1"> 
                </span><span class="s3">else</span><span class="s1">: 
                    msg = </span><span class="s2">'encoding problem for {!r}: utf-8'</span><span class="s1">.format(filename) 
                </span><span class="s3">raise </span><span class="s1">SyntaxError(msg) 
            encoding += </span><span class="s2">'-sig'</span><span class="s1"> 
        </span><span class="s3">return </span><span class="s1">encoding 
 
    first = read_or_stop() 
    </span><span class="s3">if </span><span class="s1">first.startswith(BOM_UTF8): 
        bom_found = </span><span class="s3">True</span><span class="s1"> 
        first = first[</span><span class="s5">3</span><span class="s1">:] 
        default = </span><span class="s2">'utf-8-sig'</span><span class="s1"> 
    </span><span class="s3">if not </span><span class="s1">first: 
        </span><span class="s3">return </span><span class="s1">default</span><span class="s3">, </span><span class="s1">[] 
 
    encoding = find_cookie(first) 
    </span><span class="s3">if </span><span class="s1">encoding: 
        </span><span class="s3">return </span><span class="s1">encoding</span><span class="s3">, </span><span class="s1">[first] 
    </span><span class="s3">if not </span><span class="s1">blank_re.match(first): 
        </span><span class="s3">return </span><span class="s1">default</span><span class="s3">, </span><span class="s1">[first] 
 
    second = read_or_stop() 
    </span><span class="s3">if not </span><span class="s1">second: 
        </span><span class="s3">return </span><span class="s1">default</span><span class="s3">, </span><span class="s1">[first] 
 
    encoding = find_cookie(second) 
    </span><span class="s3">if </span><span class="s1">encoding: 
        </span><span class="s3">return </span><span class="s1">encoding</span><span class="s3">, </span><span class="s1">[first</span><span class="s3">, </span><span class="s1">second] 
 
    </span><span class="s3">return </span><span class="s1">default</span><span class="s3">, </span><span class="s1">[first</span><span class="s3">, </span><span class="s1">second] 
 
 
</span><span class="s3">def </span><span class="s1">open(filename): 
    </span><span class="s0">&quot;&quot;&quot;Open a file in read only mode using the encoding detected by 
    detect_encoding(). 
    &quot;&quot;&quot;</span><span class="s1"> 
    buffer = _builtin_open(filename</span><span class="s3">, </span><span class="s2">'rb'</span><span class="s1">) 
    </span><span class="s3">try</span><span class="s1">: 
        encoding</span><span class="s3">, </span><span class="s1">lines = detect_encoding(buffer.readline) 
        buffer.seek(</span><span class="s5">0</span><span class="s1">) 
        text = TextIOWrapper(buffer</span><span class="s3">, </span><span class="s1">encoding</span><span class="s3">, </span><span class="s1">line_buffering=</span><span class="s3">True</span><span class="s1">) 
        text.mode = </span><span class="s2">'r'</span><span class="s1"> 
        </span><span class="s3">return </span><span class="s1">text 
    </span><span class="s3">except</span><span class="s1">: 
        buffer.close() 
        </span><span class="s3">raise</span><span class="s1"> 
 
 
</span><span class="s3">def </span><span class="s1">tokenize(readline): 
    </span><span class="s0">&quot;&quot;&quot; 
    The tokenize() generator requires one argument, readline, which 
    must be a callable object which provides the same interface as the 
    readline() method of built-in file objects.  Each call to the function 
    should return one line of input as bytes.  Alternatively, readline 
    can be a callable function terminating with StopIteration: 
        readline = open(myfile, 'rb').__next__  # Example of alternate readline 
 
    The generator produces 5-tuples with these members: the token type; the 
    token string; a 2-tuple (srow, scol) of ints specifying the row and 
    column where the token begins in the source; a 2-tuple (erow, ecol) of 
    ints specifying the row and column where the token ends in the source; 
    and the line on which the token was found.  The line passed is the 
    logical line; continuation lines are included. 
 
    The first token sequence will always be an ENCODING token 
    which tells you which encoding was used to decode the bytes stream. 
    &quot;&quot;&quot;</span><span class="s1"> 
    </span><span class="s6"># This import is here to avoid problems when the itertools module is not</span><span class="s1"> 
    </span><span class="s6"># built yet and tokenize is imported.</span><span class="s1"> 
    </span><span class="s3">from </span><span class="s1">itertools </span><span class="s3">import </span><span class="s1">chain</span><span class="s3">, </span><span class="s1">repeat 
    encoding</span><span class="s3">, </span><span class="s1">consumed = detect_encoding(readline) 
    rl_gen = iter(readline</span><span class="s3">, </span><span class="s4">b&quot;&quot;</span><span class="s1">) 
    empty = repeat(</span><span class="s4">b&quot;&quot;</span><span class="s1">) 
    </span><span class="s3">return </span><span class="s1">_tokenize(chain(consumed</span><span class="s3">, </span><span class="s1">rl_gen</span><span class="s3">, </span><span class="s1">empty).__next__</span><span class="s3">, </span><span class="s1">encoding) 
 
 
</span><span class="s3">def </span><span class="s1">_tokenize(readline</span><span class="s3">, </span><span class="s1">encoding): 
    lnum = parenlev = continued = </span><span class="s5">0</span><span class="s1"> 
    numchars = </span><span class="s2">'0123456789'</span><span class="s1"> 
    contstr</span><span class="s3">, </span><span class="s1">needcont = </span><span class="s2">''</span><span class="s3">, </span><span class="s5">0</span><span class="s1"> 
    contline = </span><span class="s3">None</span><span class="s1"> 
    indents = [</span><span class="s5">0</span><span class="s1">] 
 
    </span><span class="s6"># 'stashed' and 'async_*' are used for async/await parsing</span><span class="s1"> 
    stashed = </span><span class="s3">None</span><span class="s1"> 
    async_def = </span><span class="s3">False</span><span class="s1"> 
    async_def_indent = </span><span class="s5">0</span><span class="s1"> 
    async_def_nl = </span><span class="s3">False</span><span class="s1"> 
 
    </span><span class="s3">if </span><span class="s1">encoding </span><span class="s3">is not None</span><span class="s1">: 
        </span><span class="s3">if </span><span class="s1">encoding == </span><span class="s2">&quot;utf-8-sig&quot;</span><span class="s1">: 
            </span><span class="s6"># BOM will already have been stripped.</span><span class="s1"> 
            encoding = </span><span class="s2">&quot;utf-8&quot;</span><span class="s1"> 
        </span><span class="s3">yield </span><span class="s1">TokenInfo(ENCODING</span><span class="s3">, </span><span class="s1">encoding</span><span class="s3">, </span><span class="s1">(</span><span class="s5">0</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span><span class="s3">, </span><span class="s1">(</span><span class="s5">0</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span><span class="s3">, </span><span class="s2">''</span><span class="s1">) 
    </span><span class="s3">while True</span><span class="s1">:             </span><span class="s6"># loop over lines in stream</span><span class="s1"> 
        </span><span class="s3">try</span><span class="s1">: 
            line = readline() 
        </span><span class="s3">except </span><span class="s1">StopIteration: 
            line = </span><span class="s4">b''</span><span class="s1"> 
 
        </span><span class="s3">if </span><span class="s1">encoding </span><span class="s3">is not None</span><span class="s1">: 
            line = line.decode(encoding) 
        lnum += </span><span class="s5">1</span><span class="s1"> 
        pos</span><span class="s3">, </span><span class="s1">max = </span><span class="s5">0</span><span class="s3">, </span><span class="s1">len(line) 
 
        </span><span class="s3">if </span><span class="s1">contstr:                            </span><span class="s6"># continued string</span><span class="s1"> 
            </span><span class="s3">if not </span><span class="s1">line: 
                </span><span class="s3">raise </span><span class="s1">TokenError(</span><span class="s2">&quot;EOF in multi-line string&quot;</span><span class="s3">, </span><span class="s1">strstart) 
            endmatch = endprog.match(line) 
            </span><span class="s3">if </span><span class="s1">endmatch: 
                pos = end = endmatch.end(</span><span class="s5">0</span><span class="s1">) 
                </span><span class="s3">yield </span><span class="s1">TokenInfo(STRING</span><span class="s3">, </span><span class="s1">contstr + line[:end]</span><span class="s3">,</span><span class="s1"> 
                       strstart</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s1">end)</span><span class="s3">, </span><span class="s1">contline + line) 
                contstr</span><span class="s3">, </span><span class="s1">needcont = </span><span class="s2">''</span><span class="s3">, </span><span class="s5">0</span><span class="s1"> 
                contline = </span><span class="s3">None</span><span class="s1"> 
            </span><span class="s3">elif </span><span class="s1">needcont </span><span class="s3">and </span><span class="s1">line[-</span><span class="s5">2</span><span class="s1">:] != </span><span class="s2">'</span><span class="s3">\\\n</span><span class="s2">' </span><span class="s3">and </span><span class="s1">line[-</span><span class="s5">3</span><span class="s1">:] != </span><span class="s2">'</span><span class="s3">\\\r\n</span><span class="s2">'</span><span class="s1">: 
                </span><span class="s3">yield </span><span class="s1">TokenInfo(ERRORTOKEN</span><span class="s3">, </span><span class="s1">contstr + line</span><span class="s3">,</span><span class="s1"> 
                           strstart</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s1">len(line))</span><span class="s3">, </span><span class="s1">contline) 
                contstr = </span><span class="s2">''</span><span class="s1"> 
                contline = </span><span class="s3">None</span><span class="s1"> 
                </span><span class="s3">continue</span><span class="s1"> 
            </span><span class="s3">else</span><span class="s1">: 
                contstr = contstr + line 
                contline = contline + line 
                </span><span class="s3">continue</span><span class="s1"> 
 
        </span><span class="s3">elif </span><span class="s1">parenlev == </span><span class="s5">0 </span><span class="s3">and not </span><span class="s1">continued:  </span><span class="s6"># new statement</span><span class="s1"> 
            </span><span class="s3">if not </span><span class="s1">line: </span><span class="s3">break</span><span class="s1"> 
            column = </span><span class="s5">0</span><span class="s1"> 
            </span><span class="s3">while </span><span class="s1">pos &lt; max:                   </span><span class="s6"># measure leading whitespace</span><span class="s1"> 
                </span><span class="s3">if </span><span class="s1">line[pos] == </span><span class="s2">' '</span><span class="s1">: 
                    column += </span><span class="s5">1</span><span class="s1"> 
                </span><span class="s3">elif </span><span class="s1">line[pos] == </span><span class="s2">'</span><span class="s3">\t</span><span class="s2">'</span><span class="s1">: 
                    column = (column//tabsize + </span><span class="s5">1</span><span class="s1">)*tabsize 
                </span><span class="s3">elif </span><span class="s1">line[pos] == </span><span class="s2">'</span><span class="s3">\f</span><span class="s2">'</span><span class="s1">: 
                    column = </span><span class="s5">0</span><span class="s1"> 
                </span><span class="s3">else</span><span class="s1">: 
                    </span><span class="s3">break</span><span class="s1"> 
                pos += </span><span class="s5">1</span><span class="s1"> 
            </span><span class="s3">if </span><span class="s1">pos == max: 
                </span><span class="s3">break</span><span class="s1"> 
 
            </span><span class="s3">if </span><span class="s1">line[pos] </span><span class="s3">in </span><span class="s2">'#</span><span class="s3">\r\n</span><span class="s2">'</span><span class="s1">:           </span><span class="s6"># skip comments or blank lines</span><span class="s1"> 
                </span><span class="s3">if </span><span class="s1">line[pos] == </span><span class="s2">'#'</span><span class="s1">: 
                    comment_token = line[pos:].rstrip(</span><span class="s2">'</span><span class="s3">\r\n</span><span class="s2">'</span><span class="s1">) 
                    nl_pos = pos + len(comment_token) 
                    </span><span class="s3">yield </span><span class="s1">TokenInfo(COMMENT</span><span class="s3">, </span><span class="s1">comment_token</span><span class="s3">,</span><span class="s1"> 
                           (lnum</span><span class="s3">, </span><span class="s1">pos)</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s1">pos + len(comment_token))</span><span class="s3">, </span><span class="s1">line) 
                    </span><span class="s3">yield </span><span class="s1">TokenInfo(NL</span><span class="s3">, </span><span class="s1">line[nl_pos:]</span><span class="s3">,</span><span class="s1"> 
                           (lnum</span><span class="s3">, </span><span class="s1">nl_pos)</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s1">len(line))</span><span class="s3">, </span><span class="s1">line) 
                </span><span class="s3">else</span><span class="s1">: 
                    </span><span class="s3">yield </span><span class="s1">TokenInfo((NL</span><span class="s3">, </span><span class="s1">COMMENT)[line[pos] == </span><span class="s2">'#'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">line[pos:]</span><span class="s3">,</span><span class="s1"> 
                           (lnum</span><span class="s3">, </span><span class="s1">pos)</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s1">len(line))</span><span class="s3">, </span><span class="s1">line) 
                </span><span class="s3">continue</span><span class="s1"> 
 
            </span><span class="s3">if </span><span class="s1">column &gt; indents[-</span><span class="s5">1</span><span class="s1">]:           </span><span class="s6"># count indents or dedents</span><span class="s1"> 
                indents.append(column) 
                </span><span class="s3">yield </span><span class="s1">TokenInfo(INDENT</span><span class="s3">, </span><span class="s1">line[:pos]</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s1">pos)</span><span class="s3">, </span><span class="s1">line) 
            </span><span class="s3">while </span><span class="s1">column &lt; indents[-</span><span class="s5">1</span><span class="s1">]: 
                </span><span class="s3">if </span><span class="s1">column </span><span class="s3">not in </span><span class="s1">indents: 
                    </span><span class="s3">raise </span><span class="s1">IndentationError( 
                        </span><span class="s2">&quot;unindent does not match any outer indentation level&quot;</span><span class="s3">,</span><span class="s1"> 
                        (</span><span class="s2">&quot;&lt;tokenize&gt;&quot;</span><span class="s3">, </span><span class="s1">lnum</span><span class="s3">, </span><span class="s1">pos</span><span class="s3">, </span><span class="s1">line)) 
                indents = indents[:-</span><span class="s5">1</span><span class="s1">] 
 
                </span><span class="s3">if </span><span class="s1">async_def </span><span class="s3">and </span><span class="s1">async_def_indent &gt;= indents[-</span><span class="s5">1</span><span class="s1">]: 
                    async_def = </span><span class="s3">False</span><span class="s1"> 
                    async_def_nl = </span><span class="s3">False</span><span class="s1"> 
                    async_def_indent = </span><span class="s5">0</span><span class="s1"> 
 
                </span><span class="s3">yield </span><span class="s1">TokenInfo(DEDENT</span><span class="s3">, </span><span class="s2">''</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s1">pos)</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s1">pos)</span><span class="s3">, </span><span class="s1">line) 
 
            </span><span class="s3">if </span><span class="s1">async_def </span><span class="s3">and </span><span class="s1">async_def_nl </span><span class="s3">and </span><span class="s1">async_def_indent &gt;= indents[-</span><span class="s5">1</span><span class="s1">]: 
                async_def = </span><span class="s3">False</span><span class="s1"> 
                async_def_nl = </span><span class="s3">False</span><span class="s1"> 
                async_def_indent = </span><span class="s5">0</span><span class="s1"> 
 
        </span><span class="s3">else</span><span class="s1">:                                  </span><span class="s6"># continued statement</span><span class="s1"> 
            </span><span class="s3">if not </span><span class="s1">line: 
                </span><span class="s3">raise </span><span class="s1">TokenError(</span><span class="s2">&quot;EOF in multi-line statement&quot;</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)) 
            continued = </span><span class="s5">0</span><span class="s1"> 
 
        </span><span class="s3">while </span><span class="s1">pos &lt; max: 
            pseudomatch = _compile(PseudoToken).match(line</span><span class="s3">, </span><span class="s1">pos) 
            </span><span class="s3">if </span><span class="s1">pseudomatch:                                </span><span class="s6"># scan for tokens</span><span class="s1"> 
                start</span><span class="s3">, </span><span class="s1">end = pseudomatch.span(</span><span class="s5">1</span><span class="s1">) 
                spos</span><span class="s3">, </span><span class="s1">epos</span><span class="s3">, </span><span class="s1">pos = (lnum</span><span class="s3">, </span><span class="s1">start)</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s1">end)</span><span class="s3">, </span><span class="s1">end 
                </span><span class="s3">if </span><span class="s1">start == end: 
                    </span><span class="s3">continue</span><span class="s1"> 
                token</span><span class="s3">, </span><span class="s1">initial = line[start:end]</span><span class="s3">, </span><span class="s1">line[start] 
 
                </span><span class="s3">if </span><span class="s1">(initial </span><span class="s3">in </span><span class="s1">numchars </span><span class="s3">or                  </span><span class="s6"># ordinary number</span><span class="s1"> 
                    (initial == </span><span class="s2">'.' </span><span class="s3">and </span><span class="s1">token != </span><span class="s2">'.' </span><span class="s3">and </span><span class="s1">token != </span><span class="s2">'...'</span><span class="s1">)): 
                    </span><span class="s3">yield </span><span class="s1">TokenInfo(NUMBER</span><span class="s3">, </span><span class="s1">token</span><span class="s3">, </span><span class="s1">spos</span><span class="s3">, </span><span class="s1">epos</span><span class="s3">, </span><span class="s1">line) 
                </span><span class="s3">elif </span><span class="s1">initial </span><span class="s3">in </span><span class="s2">'</span><span class="s3">\r\n</span><span class="s2">'</span><span class="s1">: 
                    </span><span class="s3">if </span><span class="s1">stashed: 
                        </span><span class="s3">yield </span><span class="s1">stashed 
                        stashed = </span><span class="s3">None</span><span class="s1"> 
                    </span><span class="s3">if </span><span class="s1">parenlev &gt; </span><span class="s5">0</span><span class="s1">: 
                        </span><span class="s3">yield </span><span class="s1">TokenInfo(NL</span><span class="s3">, </span><span class="s1">token</span><span class="s3">, </span><span class="s1">spos</span><span class="s3">, </span><span class="s1">epos</span><span class="s3">, </span><span class="s1">line) 
                    </span><span class="s3">else</span><span class="s1">: 
                        </span><span class="s3">yield </span><span class="s1">TokenInfo(NEWLINE</span><span class="s3">, </span><span class="s1">token</span><span class="s3">, </span><span class="s1">spos</span><span class="s3">, </span><span class="s1">epos</span><span class="s3">, </span><span class="s1">line) 
                        </span><span class="s3">if </span><span class="s1">async_def: 
                            async_def_nl = </span><span class="s3">True</span><span class="s1"> 
 
                </span><span class="s3">elif </span><span class="s1">initial == </span><span class="s2">'#'</span><span class="s1">: 
                    </span><span class="s3">assert not </span><span class="s1">token.endswith(</span><span class="s2">&quot;</span><span class="s3">\n</span><span class="s2">&quot;</span><span class="s1">) 
                    </span><span class="s3">if </span><span class="s1">stashed: 
                        </span><span class="s3">yield </span><span class="s1">stashed 
                        stashed = </span><span class="s3">None</span><span class="s1"> 
                    </span><span class="s3">yield </span><span class="s1">TokenInfo(COMMENT</span><span class="s3">, </span><span class="s1">token</span><span class="s3">, </span><span class="s1">spos</span><span class="s3">, </span><span class="s1">epos</span><span class="s3">, </span><span class="s1">line) 
                </span><span class="s3">elif </span><span class="s1">token </span><span class="s3">in </span><span class="s1">triple_quoted: 
                    endprog = _compile(endpats[token]) 
                    endmatch = endprog.match(line</span><span class="s3">, </span><span class="s1">pos) 
                    </span><span class="s3">if </span><span class="s1">endmatch:                           </span><span class="s6"># all on one line</span><span class="s1"> 
                        pos = endmatch.end(</span><span class="s5">0</span><span class="s1">) 
                        token = line[start:pos] 
                        </span><span class="s3">yield </span><span class="s1">TokenInfo(STRING</span><span class="s3">, </span><span class="s1">token</span><span class="s3">, </span><span class="s1">spos</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s1">pos)</span><span class="s3">, </span><span class="s1">line) 
                    </span><span class="s3">else</span><span class="s1">: 
                        strstart = (lnum</span><span class="s3">, </span><span class="s1">start)           </span><span class="s6"># multiple lines</span><span class="s1"> 
                        contstr = line[start:] 
                        contline = line 
                        </span><span class="s3">break</span><span class="s1"> 
                </span><span class="s3">elif </span><span class="s1">initial </span><span class="s3">in </span><span class="s1">single_quoted </span><span class="s3">or </span><span class="s1">\ 
                    token[:</span><span class="s5">2</span><span class="s1">] </span><span class="s3">in </span><span class="s1">single_quoted </span><span class="s3">or </span><span class="s1">\ 
                    token[:</span><span class="s5">3</span><span class="s1">] </span><span class="s3">in </span><span class="s1">single_quoted: 
                    </span><span class="s3">if </span><span class="s1">token[-</span><span class="s5">1</span><span class="s1">] == </span><span class="s2">'</span><span class="s3">\n</span><span class="s2">'</span><span class="s1">:                  </span><span class="s6"># continued string</span><span class="s1"> 
                        strstart = (lnum</span><span class="s3">, </span><span class="s1">start) 
                        endprog = _compile(endpats[initial] </span><span class="s3">or</span><span class="s1"> 
                                           endpats[token[</span><span class="s5">1</span><span class="s1">]] </span><span class="s3">or</span><span class="s1"> 
                                           endpats[token[</span><span class="s5">2</span><span class="s1">]]) 
                        contstr</span><span class="s3">, </span><span class="s1">needcont = line[start:]</span><span class="s3">, </span><span class="s5">1</span><span class="s1"> 
                        contline = line 
                        </span><span class="s3">break</span><span class="s1"> 
                    </span><span class="s3">else</span><span class="s1">:                                  </span><span class="s6"># ordinary string</span><span class="s1"> 
                        </span><span class="s3">yield </span><span class="s1">TokenInfo(STRING</span><span class="s3">, </span><span class="s1">token</span><span class="s3">, </span><span class="s1">spos</span><span class="s3">, </span><span class="s1">epos</span><span class="s3">, </span><span class="s1">line) 
                </span><span class="s3">elif </span><span class="s1">initial.isidentifier():               </span><span class="s6"># ordinary name</span><span class="s1"> 
                    </span><span class="s3">if </span><span class="s1">token </span><span class="s3">in </span><span class="s1">(</span><span class="s2">'async'</span><span class="s3">, </span><span class="s2">'await'</span><span class="s1">): 
                        </span><span class="s3">if </span><span class="s1">async_def: 
                            </span><span class="s3">yield </span><span class="s1">TokenInfo( 
                                ASYNC </span><span class="s3">if </span><span class="s1">token == </span><span class="s2">'async' </span><span class="s3">else </span><span class="s1">AWAIT</span><span class="s3">,</span><span class="s1"> 
                                token</span><span class="s3">, </span><span class="s1">spos</span><span class="s3">, </span><span class="s1">epos</span><span class="s3">, </span><span class="s1">line) 
                            </span><span class="s3">continue</span><span class="s1"> 
 
                    tok = TokenInfo(NAME</span><span class="s3">, </span><span class="s1">token</span><span class="s3">, </span><span class="s1">spos</span><span class="s3">, </span><span class="s1">epos</span><span class="s3">, </span><span class="s1">line) 
                    </span><span class="s3">if </span><span class="s1">token == </span><span class="s2">'async' </span><span class="s3">and not </span><span class="s1">stashed: 
                        stashed = tok 
                        </span><span class="s3">continue</span><span class="s1"> 
 
                    </span><span class="s3">if </span><span class="s1">token == </span><span class="s2">'def'</span><span class="s1">: 
                        </span><span class="s3">if </span><span class="s1">(stashed 
                                </span><span class="s3">and </span><span class="s1">stashed.type == NAME 
                                </span><span class="s3">and </span><span class="s1">stashed.string == </span><span class="s2">'async'</span><span class="s1">): 
 
                            async_def = </span><span class="s3">True</span><span class="s1"> 
                            async_def_indent = indents[-</span><span class="s5">1</span><span class="s1">] 
 
                            </span><span class="s3">yield </span><span class="s1">TokenInfo(ASYNC</span><span class="s3">, </span><span class="s1">stashed.string</span><span class="s3">,</span><span class="s1"> 
                                            stashed.start</span><span class="s3">, </span><span class="s1">stashed.end</span><span class="s3">,</span><span class="s1"> 
                                            stashed.line) 
                            stashed = </span><span class="s3">None</span><span class="s1"> 
 
                    </span><span class="s3">if </span><span class="s1">stashed: 
                        </span><span class="s3">yield </span><span class="s1">stashed 
                        stashed = </span><span class="s3">None</span><span class="s1"> 
 
                    </span><span class="s3">yield </span><span class="s1">tok 
                </span><span class="s3">elif </span><span class="s1">initial == </span><span class="s2">'</span><span class="s3">\\</span><span class="s2">'</span><span class="s1">:                      </span><span class="s6"># continued stmt</span><span class="s1"> 
                    continued = </span><span class="s5">1</span><span class="s1"> 
                </span><span class="s3">else</span><span class="s1">: 
                    </span><span class="s3">if </span><span class="s1">initial </span><span class="s3">in </span><span class="s2">'([{'</span><span class="s1">: 
                        parenlev += </span><span class="s5">1</span><span class="s1"> 
                    </span><span class="s3">elif </span><span class="s1">initial </span><span class="s3">in </span><span class="s2">')]}'</span><span class="s1">: 
                        parenlev -= </span><span class="s5">1</span><span class="s1"> 
                    </span><span class="s3">if </span><span class="s1">stashed: 
                        </span><span class="s3">yield </span><span class="s1">stashed 
                        stashed = </span><span class="s3">None</span><span class="s1"> 
                    </span><span class="s3">yield </span><span class="s1">TokenInfo(OP</span><span class="s3">, </span><span class="s1">token</span><span class="s3">, </span><span class="s1">spos</span><span class="s3">, </span><span class="s1">epos</span><span class="s3">, </span><span class="s1">line) 
            </span><span class="s3">else</span><span class="s1">: 
                </span><span class="s3">yield </span><span class="s1">TokenInfo(ERRORTOKEN</span><span class="s3">, </span><span class="s1">line[pos]</span><span class="s3">,</span><span class="s1"> 
                           (lnum</span><span class="s3">, </span><span class="s1">pos)</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s1">pos+</span><span class="s5">1</span><span class="s1">)</span><span class="s3">, </span><span class="s1">line) 
                pos += </span><span class="s5">1</span><span class="s1"> 
 
    </span><span class="s3">if </span><span class="s1">stashed: 
        </span><span class="s3">yield </span><span class="s1">stashed 
        stashed = </span><span class="s3">None</span><span class="s1"> 
 
    </span><span class="s3">for </span><span class="s1">indent </span><span class="s3">in </span><span class="s1">indents[</span><span class="s5">1</span><span class="s1">:]:                 </span><span class="s6"># pop remaining indent levels</span><span class="s1"> 
        </span><span class="s3">yield </span><span class="s1">TokenInfo(DEDENT</span><span class="s3">, </span><span class="s2">''</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span><span class="s3">, </span><span class="s2">''</span><span class="s1">) 
    </span><span class="s3">yield </span><span class="s1">TokenInfo(ENDMARKER</span><span class="s3">, </span><span class="s2">''</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span><span class="s3">, </span><span class="s1">(lnum</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span><span class="s3">, </span><span class="s2">''</span><span class="s1">) 
 
 
</span><span class="s6"># An undocumented, backwards compatible, API for all the places in the standard</span><span class="s1"> 
</span><span class="s6"># library that expect to be able to use tokenize with strings</span><span class="s1"> 
</span><span class="s3">def </span><span class="s1">generate_tokens(readline): 
    </span><span class="s3">return </span><span class="s1">_tokenize(readline</span><span class="s3">, None</span><span class="s1">) 
 
</span><span class="s3">def </span><span class="s1">main(): 
    </span><span class="s3">import </span><span class="s1">argparse 
 
    </span><span class="s6"># Helper error handling routines</span><span class="s1"> 
    </span><span class="s3">def </span><span class="s1">perror(message): 
        print(message</span><span class="s3">, </span><span class="s1">file=sys.stderr) 
 
    </span><span class="s3">def </span><span class="s1">error(message</span><span class="s3">, </span><span class="s1">filename=</span><span class="s3">None, </span><span class="s1">location=</span><span class="s3">None</span><span class="s1">): 
        </span><span class="s3">if </span><span class="s1">location: 
            args = (filename</span><span class="s3">,</span><span class="s1">) + location + (message</span><span class="s3">,</span><span class="s1">) 
            perror(</span><span class="s2">&quot;%s:%d:%d: error: %s&quot; </span><span class="s1">% args) 
        </span><span class="s3">elif </span><span class="s1">filename: 
            perror(</span><span class="s2">&quot;%s: error: %s&quot; </span><span class="s1">% (filename</span><span class="s3">, </span><span class="s1">message)) 
        </span><span class="s3">else</span><span class="s1">: 
            perror(</span><span class="s2">&quot;error: %s&quot; </span><span class="s1">% message) 
        sys.exit(</span><span class="s5">1</span><span class="s1">) 
 
    </span><span class="s6"># Parse the arguments and options</span><span class="s1"> 
    parser = argparse.ArgumentParser(prog=</span><span class="s2">'python -m tokenize'</span><span class="s1">) 
    parser.add_argument(dest=</span><span class="s2">'filename'</span><span class="s3">, </span><span class="s1">nargs=</span><span class="s2">'?'</span><span class="s3">,</span><span class="s1"> 
                        metavar=</span><span class="s2">'filename.py'</span><span class="s3">,</span><span class="s1"> 
                        help=</span><span class="s2">'the file to tokenize; defaults to stdin'</span><span class="s1">) 
    parser.add_argument(</span><span class="s2">'-e'</span><span class="s3">, </span><span class="s2">'--exact'</span><span class="s3">, </span><span class="s1">dest=</span><span class="s2">'exact'</span><span class="s3">, </span><span class="s1">action=</span><span class="s2">'store_true'</span><span class="s3">,</span><span class="s1"> 
                        help=</span><span class="s2">'display token names using the exact type'</span><span class="s1">) 
    args = parser.parse_args() 
 
    </span><span class="s3">try</span><span class="s1">: 
        </span><span class="s6"># Tokenize the input</span><span class="s1"> 
        </span><span class="s3">if </span><span class="s1">args.filename: 
            filename = args.filename 
            </span><span class="s3">with </span><span class="s1">_builtin_open(filename</span><span class="s3">, </span><span class="s2">'rb'</span><span class="s1">) </span><span class="s3">as </span><span class="s1">f: 
                tokens = list(tokenize(f.readline)) 
        </span><span class="s3">else</span><span class="s1">: 
            filename = </span><span class="s2">&quot;&lt;stdin&gt;&quot;</span><span class="s1"> 
            tokens = _tokenize(sys.stdin.readline</span><span class="s3">, None</span><span class="s1">) 
 
        </span><span class="s6"># Output the tokenization</span><span class="s1"> 
        </span><span class="s3">for </span><span class="s1">token </span><span class="s3">in </span><span class="s1">tokens: 
            token_type = token.type 
            </span><span class="s3">if </span><span class="s1">args.exact: 
                token_type = token.exact_type 
            token_range = </span><span class="s2">&quot;%d,%d-%d,%d:&quot; </span><span class="s1">% (token.start + token.end) 
            print(</span><span class="s2">&quot;%-20s%-15s%-15r&quot; </span><span class="s1">% 
                  (token_range</span><span class="s3">, </span><span class="s1">tok_name[token_type]</span><span class="s3">, </span><span class="s1">token.string)) 
    </span><span class="s3">except </span><span class="s1">IndentationError </span><span class="s3">as </span><span class="s1">err: 
        line</span><span class="s3">, </span><span class="s1">column = err.args[</span><span class="s5">1</span><span class="s1">][</span><span class="s5">1</span><span class="s1">:</span><span class="s5">3</span><span class="s1">] 
        error(err.args[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">filename</span><span class="s3">, </span><span class="s1">(line</span><span class="s3">, </span><span class="s1">column)) 
    </span><span class="s3">except </span><span class="s1">TokenError </span><span class="s3">as </span><span class="s1">err: 
        line</span><span class="s3">, </span><span class="s1">column = err.args[</span><span class="s5">1</span><span class="s1">] 
        error(err.args[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">filename</span><span class="s3">, </span><span class="s1">(line</span><span class="s3">, </span><span class="s1">column)) 
    </span><span class="s3">except </span><span class="s1">SyntaxError </span><span class="s3">as </span><span class="s1">err: 
        error(err</span><span class="s3">, </span><span class="s1">filename) 
    </span><span class="s3">except </span><span class="s1">OSError </span><span class="s3">as </span><span class="s1">err: 
        error(err) 
    </span><span class="s3">except </span><span class="s1">KeyboardInterrupt: 
        print(</span><span class="s2">&quot;interrupted</span><span class="s3">\n</span><span class="s2">&quot;</span><span class="s1">) 
    </span><span class="s3">except </span><span class="s1">Exception </span><span class="s3">as </span><span class="s1">err: 
        perror(</span><span class="s2">&quot;unexpected error: %s&quot; </span><span class="s1">% err) 
        </span><span class="s3">raise</span><span class="s1"> 
 
</span><span class="s3">if </span><span class="s1">__name__ == </span><span class="s2">&quot;__main__&quot;</span><span class="s1">: 
    main() 
</span></pre>
</body>
</html>